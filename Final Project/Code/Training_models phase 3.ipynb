{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7HDA8A-PWui",
    "outputId": "eb2f9467-1b66-4925-9040-36b0494bfc5d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gz2goxF7PWuk",
    "outputId": "a904d51e-0bce-4f71-8ae1-2d0b7c908668"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/SPEECH/Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhbERoZePWul",
    "outputId": "4df582e5-0eef-41cf-fa3c-4415d7d65c8f"
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "uYyFxJMLPWul"
   },
   "source": [
    "This is the main part of the code. It makes models by phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JlvEdGToPWum",
    "ExecuteTime": {
     "end_time": "2023-08-24T01:11:43.707327300Z",
     "start_time": "2023-08-24T01:11:40.483560900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\torchaudio\\models\\decoder\\_ctc_decoder.py:62: UserWarning: The built-in flashlight integration is deprecated, and will be removed in future release. Please install flashlight-text. https://pypi.org/project/flashlight-text/ For the detail of CTC decoder migration, please see https://github.com/pytorch/audio/issues/3088.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tokens list:  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ', '?']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ', '?']\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import PreProcessing, PhaseOneModel, PhaseTwoModel, PhaseThreeModel, Evaluating, PhaseFourModel\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1yWpWRavPWun",
    "ExecuteTime": {
     "end_time": "2023-08-24T01:11:46.389803900Z",
     "start_time": "2023-08-24T01:11:43.707327300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mronko\u001B[0m (\u001B[33mrons-team\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "# Sweep configuration\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {'name': 'WER', 'goal': 'minimize'},\n",
    "    'name': 'PhaseFourModel',\n",
    "    'parameters': {\n",
    "        'wandb_init': {'value': True},\n",
    "        'epochs': {'value': 400},\n",
    "        'learning_rate': {'max': 0.01, 'min': 0.00001},\n",
    "        'batch_size': {'value': 64},\n",
    "        'n_cnn_layers': {'value': 1},  # Fixed value\n",
    "        'n_rnn_layers': {'value': 1},  # Fixed value\n",
    "        'rnn_dim': {'value': 64},\n",
    "        'n_class': {'value': PreProcessing.NUM_CLASSES + 1},\n",
    "        'n_feats': {'value': 128},\n",
    "        'stride': {'value': 2},\n",
    "        'dropout': {'values': [0, 0.1, 0.3]},\n",
    "        'lm_weight': {'min': 0, 'max': 3},\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "84wJwTIwPWun",
    "ExecuteTime": {
     "end_time": "2023-08-24T01:11:46.436810700Z",
     "start_time": "2023-08-24T01:11:46.389803900Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    def __init__(self, wandb_config=None):\n",
    "        if wandb_config:\n",
    "            self = wandb.config\n",
    "        else:\n",
    "            learning_rate: float = 0.01\n",
    "            epochs: int = 300\n",
    "            batch_size: int = 32\n",
    "            wandb_init: bool = False\n",
    "\n",
    "            hyperparams = {\n",
    "                \"n_cnn_layers\": 1,\n",
    "                \"n_rnn_layers\": 1,\n",
    "                \"rnn_dim\": 128,\n",
    "                \"n_class\": PreProcessing.NUM_CLASSES+1,\n",
    "                \"n_feats\": 128,\n",
    "                \"stride\": 2,\n",
    "                \"dropout\": 0.5,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2Eg6HO9RPWun",
    "ExecuteTime": {
     "end_time": "2023-08-24T01:11:46.436810700Z",
     "start_time": "2023-08-24T01:11:46.405305500Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(PhaseNumber, config=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using {} device\".format(device))\n",
    "    architecture = PhaseNumber + 'Model'\n",
    "    # turn on and off wandb logging\n",
    "    # start a new wandb run to track this script\n",
    "    config = config\n",
    "\n",
    "    test_dataloader = None\n",
    "\n",
    "    # Now you can create a Dataset and DataLoader for your data\n",
    "    # wavs, txts = PreProcessing.load_data(mode='train', data_path=PreProcessing.DATA_PATH)\n",
    "    #\n",
    "    # dataset = PreProcessing.AudioDatasetV3(wavs, txts)\n",
    "    # train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size,\n",
    "    #                                                shuffle=True,\n",
    "    #                                                collate_fn=lambda x:\n",
    "    #                                                PreProcessing.process_data(x))\n",
    "    # wavs, txts = PreProcessing.load_data(mode='test', data_path=PreProcessing.DATA_PATH)\n",
    "    # test_dataset = PreProcessing.AudioDatasetV3(wavs, txts)\n",
    "    # test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size,\n",
    "    #                                               shuffle=False,\n",
    "    #                                               collate_fn=lambda x:\n",
    "    #                                               PreProcessing.process_data(x)\n",
    "    #                                               )\n",
    "\n",
    "    # model = PhaseThreeModel.PhaseThreeModel(config,\n",
    "    #                                         n_cnn_layers=config.hyperparams['n_cnn_layers'],\n",
    "    #                                         n_rnn_layers=config.hyperparams['n_rnn_layers'],\n",
    "    #                                         rnn_dim=config.hyperparams['rnn_dim'],\n",
    "    #                                         n_class=config.hyperparams['n_class'],\n",
    "    #                                         n_feats=config.hyperparams['n_feats'],\n",
    "    #                                         stride=config.hyperparams['stride'],\n",
    "    #                                         dropout=config.hyperparams['dropout'],\n",
    "    #                                         )\n",
    "    # model = PhaseFourModel.PhaseFourModel(config)\n",
    "    wavs, txts = PreProcessing.load_data(mode='train', data_path=PreProcessing.DATA_PATH)\n",
    "    dataset = PreProcessing.AudioDatasetV2(wavs, txts)\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size,\n",
    "                                                   shuffle=True)\n",
    "\n",
    "    wavs, txts = PreProcessing.load_data(mode='test', data_path=PreProcessing.DATA_PATH)\n",
    "    test_dataset = PreProcessing.AudioDatasetV2(wavs, txts)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size,\n",
    "                                                  shuffle=False)\n",
    "    model = PhaseTwoModel.PhaseTwoModel()\n",
    "\n",
    "    return model, train_dataloader, test_dataloader, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cctKE1OYPWup",
    "ExecuteTime": {
     "end_time": "2023-08-24T01:11:46.436810700Z",
     "start_time": "2023-08-24T01:11:46.436810700Z"
    }
   },
   "outputs": [],
   "source": [
    "# model, train_dataloader, test_dataloader, device = create_model(\"PhaseTwo\",\n",
    "#                                                                     config=Config(wandb_init=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JCBZCO3qPWup",
    "ExecuteTime": {
     "end_time": "2023-08-24T01:11:46.471970700Z",
     "start_time": "2023-08-24T01:11:46.436810700Z"
    }
   },
   "outputs": [],
   "source": [
    "# criterion = torch.nn.CTCLoss(blank=PreProcessing.BLANK_IDX).to(device)\n",
    "# PhaseThreeModel.train_model_phase_three(model, train_dataloader, criterion, device, test_dataloader, config=Config(\n",
    "#     wandb_init=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZtXxv6_SPWuq",
    "ExecuteTime": {
     "end_time": "2023-08-24T01:11:46.477592100Z",
     "start_time": "2023-08-24T01:11:46.456323Z"
    }
   },
   "outputs": [],
   "source": [
    "def main_train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        # config.extend({'wandb_init': True})\n",
    "        print(config)\n",
    "        model, train_dataloader, test_dataloader, device = create_model(\"PhaseFour\",\n",
    "                                                                        config=config)\n",
    "        criterion = torch.nn.CTCLoss(blank=PreProcessing.BLANK_IDX).to(device)\n",
    "        PhaseThreeModel.train_model_phase_three(model, train_dataloader, criterion, device, test_dataloader, config=config)\n",
    "        torch.save(model.state_dict(), f\"PhaseFourModel_{wandb.run.name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ScuuoXVhPWuq",
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 0a6qigdr\n",
      "Sweep URL: https://wandb.ai/rons-team/speechRecProj/sweeps/0a6qigdr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: znzxjdo1 with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdropout: 0.1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 400\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.008844704238529656\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlm_weight: 0.1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tn_class: 28\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tn_cnn_layers: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tn_feats: 128\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tn_rnn_layers: 1\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \trnn_dim: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tstride: 2\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \twandb_init: True\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: W&B API key is configured. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\PC\\Documents\\ACADEMY\\6th semester\\Speech Processing\\SPEECH\\Final Project\\Code\\wandb\\run-20230824_041156-znzxjdo1</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/rons-team/speechRecProj/runs/znzxjdo1' target=\"_blank\">classic-sweep-1</a></strong> to <a href='https://wandb.ai/rons-team/speechRecProj' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rons-team/speechRecProj/sweeps/0a6qigdr' target=\"_blank\">https://wandb.ai/rons-team/speechRecProj/sweeps/0a6qigdr</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/rons-team/speechRecProj' target=\"_blank\">https://wandb.ai/rons-team/speechRecProj</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/rons-team/speechRecProj/sweeps/0a6qigdr' target=\"_blank\">https://wandb.ai/rons-team/speechRecProj/sweeps/0a6qigdr</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/rons-team/speechRecProj/runs/znzxjdo1' target=\"_blank\">https://wandb.ai/rons-team/speechRecProj/runs/znzxjdo1</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:znzxjdo1) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.186922…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91cb27cde4e749c5ac6d91c48d3c6f4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">classic-sweep-1</strong> at: <a href='https://wandb.ai/rons-team/speechRecProj/runs/znzxjdo1' target=\"_blank\">https://wandb.ai/rons-team/speechRecProj/runs/znzxjdo1</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20230824_041156-znzxjdo1\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:znzxjdo1). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96b02606770c4307bdc5b43307aaa234"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\PC\\Documents\\ACADEMY\\6th semester\\Speech Processing\\SPEECH\\Final Project\\Code\\wandb\\run-20230824_041202-znzxjdo1</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/rons-team/speechRecProj/runs/znzxjdo1' target=\"_blank\">classic-sweep-1</a></strong> to <a href='https://wandb.ai/rons-team/speechRecProj' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rons-team/speechRecProj/sweeps/0a6qigdr' target=\"_blank\">https://wandb.ai/rons-team/speechRecProj/sweeps/0a6qigdr</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/rons-team/speechRecProj' target=\"_blank\">https://wandb.ai/rons-team/speechRecProj</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/rons-team/speechRecProj/sweeps/0a6qigdr' target=\"_blank\">https://wandb.ai/rons-team/speechRecProj/sweeps/0a6qigdr</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/rons-team/speechRecProj/runs/znzxjdo1' target=\"_blank\">https://wandb.ai/rons-team/speechRecProj/runs/znzxjdo1</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 400, 'learning_rate': 0.008844704238529656, 'lm_weight': 0.1, 'n_class': 28, 'n_cnn_layers': 1, 'n_feats': 128, 'n_rnn_layers': 1, 'rnn_dim': 64, 'stride': 2, 'wandb_init': True}\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Documents\\ACADEMY\\6th semester\\Speech Processing\\SPEECH\\Final Project\\Code\\LSTMCorpus.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_sequence = torch.tensor(sequence)\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Input:  torch.Size([1, 128, 1051]) First Label:  tensor([13, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]) First Label Length:  2\n",
      "Input txt: noaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      " \n",
      " \n",
      "model preds:  torch.Size([1, 131, 28])\n",
      "Model Output:  vvvvvveaajevvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\n",
      "Epoch:  0 / 400  ( 0.0 %)\n"
     ]
    }
   ],
   "source": [
    "def train_sweep():\n",
    "    with wandb.init() as run:\n",
    "        # You can call your main training function here, passing the config\n",
    "        main_train()  # Assuming 'train' is the main training function\n",
    "\n",
    "# Running the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project='speechRecProj')  # Create the sweep\n",
    "wandb.agent(sweep_id, train_sweep)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
