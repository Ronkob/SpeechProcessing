{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T19:32:20.652370900Z",
     "start_time": "2023-08-21T19:32:20.605494500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/SPEECH/Code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install jiwer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the main part of the code. It makes models by phases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import PreProcessing, PhaseOneModel, PhaseTwoModel, PhaseThreeModel, Evaluating\n",
    "import torch\n",
    "import wandb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T21:23:48.878996900Z",
     "start_time": "2023-08-21T21:23:43.514444700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    learning_rate: float = 5e-4\n",
    "    epochs: int = 300\n",
    "    batch_size: int = 32\n",
    "    wandb_init: bool = False\n",
    "\n",
    "    hyperparams = {\n",
    "        \"n_cnn_layers\": 1,\n",
    "        \"n_rnn_layers\": 1,\n",
    "        \"rnn_dim\": 128,\n",
    "        \"n_class\": PreProcessing.NUM_CLASSES+1,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\": 2,\n",
    "        \"dropout\": 0.5,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T21:23:48.894618800Z",
     "start_time": "2023-08-21T21:23:48.878996900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def create_model(PhaseNumber, phase_model_class, config=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using {} device\".format(device))\n",
    "    architecture = PhaseNumber + 'Model'\n",
    "    # turn on and off wandb logging\n",
    "    # start a new wandb run to track this script\n",
    "    if config.wandb_init:\n",
    "        wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project=\"speechRecProj\",\n",
    "\n",
    "            # track hyperparameters and run metadata\n",
    "            config={\n",
    "                \"learning_rate\": config.learning_rate,\n",
    "                \"architecture\": architecture,\n",
    "                \"epochs\": config.epochs,\n",
    "                \"batch_size\": config.batch_size,\n",
    "                \"hyperparams\": config.hyperparams,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    test_dataloader = None\n",
    "    wavs, txts = PreProcessing.load_data(mode='train', data_path=PreProcessing.DATA_PATH)\n",
    "\n",
    "    # Now you can create a Dataset and DataLoader for your data\n",
    "    dataset = PreProcessing.AudioDatasetV3(wavs, txts)\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   collate_fn=lambda x:\n",
    "                                                   PreProcessing.process_data(x))\n",
    "    wavs, txts = PreProcessing.load_data(mode='test', data_path=PreProcessing.DATA_PATH)\n",
    "    test_dataset = PreProcessing.AudioDatasetV3(wavs, txts)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size,\n",
    "                                                  collate_fn=lambda x:\n",
    "                                                  PreProcessing.process_data(x)\n",
    "                                                  )\n",
    "\n",
    "\n",
    "    # dataset = PreProcessing.AudioDatasetV2(wavs, txts)\n",
    "    # train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=config.batch_size,\n",
    "    #                                                shuffle=True)\n",
    "\n",
    "    model = PhaseThreeModel.PhaseThreeModel(config,\n",
    "                                            n_cnn_layers=config.hyperparams['n_cnn_layers'],\n",
    "                                            n_rnn_layers=config.hyperparams['n_rnn_layers'],\n",
    "                                            rnn_dim=config.hyperparams['rnn_dim'],\n",
    "                                            n_class=config.hyperparams['n_class'],\n",
    "                                            n_feats=config.hyperparams['n_feats'],\n",
    "                                            stride=config.hyperparams['stride'],\n",
    "                                            dropout=config.hyperparams['dropout'],\n",
    "                                            )\n",
    "\n",
    "    return model, train_dataloader, test_dataloader, device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T21:23:48.910250100Z",
     "start_time": "2023-08-21T21:23:48.894618800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model, train_dataloader, test_dataloader, device = create_model(\"PhaseThree\",\n",
    "                                                                    PhaseThreeModel.PhaseThreeModel,\n",
    "                                                                    config=Config(wandb_init=False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = torch.nn.CTCLoss(blank=PreProcessing.BLANK_IDX).to(device)\n",
    "PhaseThreeModel.train_model_phase_three(model, train_dataloader, criterion, device, config=Config(\n",
    "    wandb_init=False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# function ClickConnect(){\n",
    "# console.log(\"Working\");\n",
    "# document.querySelector(\"colab-toolbar-button#connect\").click()\n",
    "# }setInterval(ClickConnect,60000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "import torch\n",
    "import time\n",
    "import gc\n",
    "!pip install pynvml\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def wait_until_enough_gpu_memory(min_memory_available, max_retries=10, sleep_time=5):\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(torch.cuda.current_device())\n",
    "\n",
    "    for _ in range(max_retries):\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        if info.free >= min_memory_available:\n",
    "            break\n",
    "        print(f\"Waiting for {min_memory_available} bytes of free GPU memory. Retrying in {sleep_time} seconds...\")\n",
    "        time.sleep(sleep_time)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Failed to acquire {min_memory_available} bytes of free GPU memory after {max_retries} retries.\")\n",
    "\n",
    "# Usage example\n",
    "min_memory_available = 2 * 1024 * 1024 * 1024 * 5 # 10GB\n",
    "clear_gpu_memory()\n",
    "wait_until_enough_gpu_memory(min_memory_available)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
