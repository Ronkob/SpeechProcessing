{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-22T20:49:03.561063300Z",
     "start_time": "2023-05-22T20:48:54.990530900Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from abc import abstractmethod\n",
    "\n",
    "import librosa as librosa\n",
    "import pandas as pd\n",
    "import torch\n",
    "from enum import Enum\n",
    "import typing as tp\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "from torch.nn.functional import cross_entropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ex2.Ex2.genre_classifier import Genre\n",
    "import json\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_wav_files(json_file_path):\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Create an empty DataFrame\n",
    "    df = pd.DataFrame(columns=['label', 'audio', 'sr'])\n",
    "\n",
    "    # Iterate over first 50 items in the JSON data\n",
    "    for item in data:\n",
    "        path = item['path']\n",
    "        label = item['label']\n",
    "        label = str.replace(label, '-', '_')\n",
    "        label = Genre[label.upper()].value\n",
    "        # Load the audio file using librosa\n",
    "        audio, sr = librosa.load(path, sr=None)\n",
    "\n",
    "        # Append the path, label, and audio to the DataFrameu78yt6r5fe4\n",
    "        df = df.append({'label': label, 'audio': audio, 'sr': sr}, ignore_index=True)\n",
    "\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T20:49:03.583476300Z",
     "start_time": "2023-05-22T20:49:03.569581300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# load both train and test data, then combine them\n",
    "train_df = load_wav_files('jsons/train.json')\n",
    "test_df = load_wav_files('jsons/test.json')\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T20:49:26.459465100Z",
     "start_time": "2023-05-22T20:49:03.580472500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(1198, 266112)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.asarray(df['audio'].tolist())\n",
    "labels = np.asarray(df['label'].tolist())\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T20:49:27.274911700Z",
     "start_time": "2023-05-22T20:49:26.420648800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# extract features not efficient but works"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "def extract_advanced_features(wavs):\n",
    "    all_features = []\n",
    "\n",
    "    for wav in wavs:\n",
    "        print(\"start wav\")\n",
    "        # Calculate MFCC\n",
    "        mfccs = librosa.feature.mfcc(y=wav, sr=22050, n_mfcc=13)\n",
    "\n",
    "        # Calculate spectral contrast\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=wav, sr=22050)\n",
    "\n",
    "        # Calculate chroma features\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=wav, sr=22050)\n",
    "\n",
    "        # Calculate tonnetz\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(wav), sr=22050)\n",
    "\n",
    "        # Calculate spectral bandwidth\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=wav, sr=22050)\n",
    "\n",
    "        # Calculate spectral flatness\n",
    "        spec_flatness = librosa.feature.spectral_flatness(y=wav)\n",
    "\n",
    "        # Calculate zero crossing rate\n",
    "        zcr = librosa.feature.zero_crossing_rate(wav)\n",
    "\n",
    "        # Calculate RMS\n",
    "        rms = librosa.feature.rms(y=wav)\n",
    "\n",
    "        # Calculate spectral rolloff\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=wav, sr=22050)\n",
    "\n",
    "        # Calculate spectral centroid\n",
    "        centroid = librosa.feature.spectral_centroid(y=wav, sr=22050)\n",
    "\n",
    "        # Calculate spectral contrast\n",
    "        contrast = librosa.feature.spectral_contrast(y=wav, sr=22050)\n",
    "\n",
    "        # Stack all features\n",
    "        features = np.vstack([mfccs, spectral_contrast, chroma_stft, tonnetz, spec_bw, spec_flatness, zcr, rms, rolloff, centroid, contrast])\n",
    "\n",
    "        # Calculate various statistics for each feature\n",
    "        feature_stats = np.hstack([np.mean(features, axis=1),\n",
    "                                   np.std(features, axis=1),\n",
    "                                   np.median(features, axis=1),\n",
    "                                   np.min(features, axis=1),\n",
    "                                   np.max(features, axis=1),\n",
    "                                   scipy.stats.skew(features, axis=1)])\n",
    "\n",
    "        all_features.append(feature_stats)\n",
    "\n",
    "    return np.array(all_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T21:49:08.833535300Z",
     "start_time": "2023-05-22T21:49:08.813852900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n",
      "start wav\n"
     ]
    }
   ],
   "source": [
    "features = extract_advanced_features(data[:50])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T21:50:34.691642200Z",
     "start_time": "2023-05-22T21:49:12.737322900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 306)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T21:51:10.963409200Z",
     "start_time": "2023-05-22T21:51:10.901970400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class LogisticRegressor:\n",
    "    def __init__(self, input_dim: int, num_classes: int):\n",
    "        self.weights = torch.zeros(input_dim, num_classes, requires_grad=False)\n",
    "        self.bias = torch.randn(num_classes, requires_grad=False)\n",
    "\n",
    "    def forward(self, feats: torch.Tensor) -> torch.Tensor:\n",
    "        x =  torch.mm(feats, self.weights) + self.bias\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def softmax(self, z):\n",
    "        e_z = torch.exp(z - torch.max(z, dim=1, keepdim=True).values)\n",
    "        return e_z / torch.sum(e_z, dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "    def compute_gradients(self, feats, output_scores, labels):\n",
    "        num_samples = feats.shape[0]\n",
    "        output_scores[range(num_samples), labels] -= 1\n",
    "        output_scores /= num_samples\n",
    "\n",
    "        grad_weights = torch.mm(feats.T, output_scores)\n",
    "        grad_bias = torch.sum(output_scores, dim=0)\n",
    "\n",
    "        return grad_weights, grad_bias\n",
    "\n",
    "    def update_weights(self, grad_weights, grad_bias, lr):\n",
    "        self.weights -= lr * grad_weights\n",
    "        self.bias -= lr * grad_bias\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100, batch_size=32, lr=0.01):\n",
    "        # training loop\n",
    "        print(epochs)\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                data = X_train[i:i + batch_size]\n",
    "                # forward pass\n",
    "                output_scores = self.forward(data)\n",
    "                # backward pass and optimization\n",
    "                # self.backward(data, output_scores, y_train[i:i + batch_size])\n",
    "\n",
    "\n",
    "            # print loss every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                output_scores = self.forward(X_train)\n",
    "                loss = torch.nn.functional.cross_entropy(output_scores, y_train)\n",
    "                print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "\n",
    "def train_and_test_model(features: np.ndarray, labels: np.ndarray, epochs = 100, batch_size = 32):\n",
    "    # convert features and labels to torch tensors\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    # split the features and labels into a training set and a testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    # get the number of features from the feature data\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    # get the number of unique classes from the labels\n",
    "    num_classes = len(torch.unique(labels))\n",
    "\n",
    "    # create the model\n",
    "    model = LogisticRegressor(input_dim, num_classes)\n",
    "\n",
    "    model.train(features, labels, epochs, batch_size)\n",
    "\n",
    "    # testing the model\n",
    "    test_output_scores = model.forward(X_test)\n",
    "    _, predicted = torch.max(test_output_scores.data, 1)\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "    test_accuracy = correct / len(y_test)\n",
    "    print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T21:38:53.563371600Z",
     "start_time": "2023-05-22T21:38:53.487694800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def visualize_model_features(model):\n",
    "    weights = model.weights.detach().numpy()\n",
    "\n",
    "    # Average weights across output classes\n",
    "    average_weights = abs(np.mean(weights, axis=1))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # plot a bar plot, but group the x axis by feature type (6 consecutive features), and stack the bars by output class\n",
    "    plt.bar(np.arange(len(average_weights)), average_weights)\n",
    "    plt.xticks(np.arange(0, len(average_weights), 6) + 2.5,\n",
    "               ['mfccs', 'spectral_contrast', 'chroma_stft', 'tonnetz', 'spec_bw', 'spec_flatness', 'zcr', 'rms', 'rolloff'])\n",
    "    plt.xlabel('Feature type')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T20:52:21.517912200Z",
     "start_time": "2023-05-22T20:52:21.483488100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 306]) torch.Size([40]) torch.Size([10, 306]) torch.Size([10])\n",
      "100\n",
      "Epoch 10/100, Loss: 0.9714447855949402\n",
      "Epoch 20/100, Loss: 0.791444718837738\n",
      "Epoch 30/100, Loss: 0.6914446949958801\n",
      "Epoch 40/100, Loss: 0.6714447140693665\n",
      "Epoch 50/100, Loss: 0.6314446330070496\n",
      "Epoch 60/100, Loss: 0.651444673538208\n",
      "Epoch 70/100, Loss: 0.6714446544647217\n",
      "Epoch 80/100, Loss: 0.8514447808265686\n",
      "Epoch 90/100, Loss: 0.651444673538208\n",
      "Epoch 100/100, Loss: 0.651444673538208\n",
      "Test accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "model = train_and_test_model(features, labels[:50], epochs=100)\n",
    "# visualize_model_features(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T21:51:41.171832400Z",
     "start_time": "2023-05-22T21:51:40.981438700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
